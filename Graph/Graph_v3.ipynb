{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import igraph as ig\n",
    "\n",
    "import folium\n",
    "from folium import Map, PolyLine, CircleMarker\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.vector_layers import CircleMarker, PolyLine\n",
    "from shapely.geometry import Point, LineString\n",
    "from pyvis.network import Network\n",
    "from collections import Counter\n",
    "\n",
    "import community\n",
    "from community import community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import leidenalg\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining directories to extract files from // store files to \n",
    "\n",
    "dataframes_dir = '/Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/filtered_dataframes/'\n",
    "graphs_dir = '/Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/graphs/'\n",
    "maps_dir = '/Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/'\n",
    "info_dir = '/Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromLatitude</th>\n",
       "      <th>FromLongitude</th>\n",
       "      <th>ToLatitude</th>\n",
       "      <th>ToLongitude</th>\n",
       "      <th>RouteDistance</th>\n",
       "      <th>FromLocation</th>\n",
       "      <th>ToLocation</th>\n",
       "      <th>FromCity</th>\n",
       "      <th>ToCity</th>\n",
       "      <th>FromCountry</th>\n",
       "      <th>ToCountry</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>RouteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.71873</td>\n",
       "      <td>11.82862</td>\n",
       "      <td>57.71873</td>\n",
       "      <td>11.82862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>968</td>\n",
       "      <td>77695</td>\n",
       "      <td>Skara</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12414</td>\n",
       "      <td>240268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.47409</td>\n",
       "      <td>9.15797</td>\n",
       "      <td>55.47409</td>\n",
       "      <td>9.15797</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8409</td>\n",
       "      <td>2301</td>\n",
       "      <td>Horsens</td>\n",
       "      <td>Vejen</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>12895</td>\n",
       "      <td>195961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.71877</td>\n",
       "      <td>11.82920</td>\n",
       "      <td>57.69555</td>\n",
       "      <td>11.85303</td>\n",
       "      <td>5.714</td>\n",
       "      <td>30251</td>\n",
       "      <td>70713</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12895</td>\n",
       "      <td>172307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.71877</td>\n",
       "      <td>11.82920</td>\n",
       "      <td>57.71225</td>\n",
       "      <td>11.96575</td>\n",
       "      <td>12.148</td>\n",
       "      <td>30251</td>\n",
       "      <td>70709</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12895</td>\n",
       "      <td>132002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.72323</td>\n",
       "      <td>11.85834</td>\n",
       "      <td>57.72323</td>\n",
       "      <td>11.85834</td>\n",
       "      <td>0.000</td>\n",
       "      <td>945</td>\n",
       "      <td>11641</td>\n",
       "      <td>DESTELDONK</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12895</td>\n",
       "      <td>115222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57.71499</td>\n",
       "      <td>11.82177</td>\n",
       "      <td>57.71499</td>\n",
       "      <td>11.82177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9483</td>\n",
       "      <td>495</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12417</td>\n",
       "      <td>114706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.63623</td>\n",
       "      <td>9.77687</td>\n",
       "      <td>56.63623</td>\n",
       "      <td>9.77687</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22240</td>\n",
       "      <td>2300</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Hobro</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>4467</td>\n",
       "      <td>78664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55.72639</td>\n",
       "      <td>-3.95987</td>\n",
       "      <td>55.72614</td>\n",
       "      <td>-3.96033</td>\n",
       "      <td>0.006</td>\n",
       "      <td>9230</td>\n",
       "      <td>20364</td>\n",
       "      <td>Larkhall</td>\n",
       "      <td>LARKHALL</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>8062</td>\n",
       "      <td>69049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.71225</td>\n",
       "      <td>11.96575</td>\n",
       "      <td>57.71877</td>\n",
       "      <td>11.82920</td>\n",
       "      <td>14.361</td>\n",
       "      <td>30257</td>\n",
       "      <td>70696</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12415</td>\n",
       "      <td>51297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57.71872</td>\n",
       "      <td>11.82861</td>\n",
       "      <td>57.71872</td>\n",
       "      <td>11.82861</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11592</td>\n",
       "      <td>81480</td>\n",
       "      <td>Skara</td>\n",
       "      <td>Göteborg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>12414</td>\n",
       "      <td>50553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FromLatitude  FromLongitude  ToLatitude  ToLongitude  RouteDistance  \\\n",
       "0      57.71873       11.82862    57.71873     11.82862          0.000   \n",
       "1      55.47409        9.15797    55.47409      9.15797          0.000   \n",
       "2      57.71877       11.82920    57.69555     11.85303          5.714   \n",
       "3      57.71877       11.82920    57.71225     11.96575         12.148   \n",
       "4      57.72323       11.85834    57.72323     11.85834          0.000   \n",
       "5      57.71499       11.82177    57.71499     11.82177          0.000   \n",
       "6      56.63623        9.77687    56.63623      9.77687          0.000   \n",
       "7      55.72639       -3.95987    55.72614     -3.96033          0.006   \n",
       "8      57.71225       11.96575    57.71877     11.82920         14.361   \n",
       "9      57.71872       11.82861    57.71872     11.82861          0.000   \n",
       "\n",
       "   FromLocation  ToLocation    FromCity      ToCity     FromCountry  \\\n",
       "0           968       77695       Skara    Göteborg          Sweden   \n",
       "1          8409        2301     Horsens       Vejen         Denmark   \n",
       "2         30251       70713  Gothenburg    Göteborg          Sweden   \n",
       "3         30251       70709  Gothenburg    Göteborg          Sweden   \n",
       "4           945       11641  DESTELDONK    Göteborg          Sweden   \n",
       "5          9483         495    Göteborg    Göteborg          Sweden   \n",
       "6         22240        2300      Dublin       Hobro         Denmark   \n",
       "7          9230       20364    Larkhall    LARKHALL  United Kingdom   \n",
       "8         30257       70696    Göteborg  Gothenburg          Sweden   \n",
       "9         11592       81480       Skara    Göteborg          Sweden   \n",
       "\n",
       "        ToCountry  CustomerName  RouteCount  \n",
       "0          Sweden         12414      240268  \n",
       "1         Denmark         12895      195961  \n",
       "2          Sweden         12895      172307  \n",
       "3          Sweden         12895      132002  \n",
       "4          Sweden         12895      115222  \n",
       "5          Sweden         12417      114706  \n",
       "6         Denmark          4467       78664  \n",
       "7  United Kingdom          8062       69049  \n",
       "8          Sweden         12415       51297  \n",
       "9          Sweden         12414       50553  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 0) Prepare dataset for Graph building\n",
    "\n",
    "# Loading dataset\n",
    "\n",
    "df_routes = pd.read_csv(\"/Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/df_routes.csv\")\n",
    "df_routes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Building functions to interactively filter the dataset\n",
    "\n",
    "\n",
    "## 1.1) Create function to filter for country and distance\n",
    "\n",
    "def filter_country_distance(df, country, min_distance, max_distance=None):\n",
    "    \"\"\"\n",
    "    Filters a given input dataframe based on a specified country and a range of route distances.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing 'FromCountry', 'ToCountry', and 'RouteDistance' columns.\n",
    "    country (str): The country to filter the data for; we include not only domestic deliveries in the filter, but also deliveries that have only either the pick-up or drop-off in the specified country.\n",
    "    min_distance (float): The minimum route distance to include in the filtered data.\n",
    "    max_distance (float, optional): The maximum route distance to include in the filtered data. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new dataframe filtered based on the specified country and distance range.\n",
    "    \"\"\"\n",
    "\n",
    "    country_filter = (df['FromCountry'] == country) | (df['ToCountry'] == country)\n",
    "    if max_distance is not None:\n",
    "        distance_filter = (df['RouteDistance'] >= min_distance) & (df['RouteDistance'] <= max_distance)\n",
    "    else:\n",
    "        distance_filter = (df['RouteDistance'] >= min_distance)\n",
    "    \n",
    "    filtered_df = df[country_filter & distance_filter]\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "## 1.2) Create function to export filtered dataframes\n",
    "\n",
    "def export_filtered_dataframes(filtered_dataframes, directory):\n",
    "\n",
    "    \"\"\"\n",
    "    Exports the filtered dataframes from a dictionary to a specified directory as CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    filtered_dataframes (dict): A dictionary containing the filtered dataframes with their respective keys.\n",
    "    directory (str): The directory where the filtered dataframes should be saved as CSV files.\n",
    "    \"\"\"\n",
    "     \n",
    "    for key, df in filtered_dataframes.items():\n",
    "        filename = os.path.join(directory, f\"{key}.csv\")\n",
    "        \n",
    "        if not os.path.exists(filename):\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Data frame {key} has been exported to {filename}.\")\n",
    "        else:\n",
    "            print(f\"Data frame {key} already exists at {filename}.\")\n",
    "\n",
    "\n",
    "## 1.3) Create function that requests  user input of country\n",
    "\n",
    "def get_country_input(prompt):\n",
    "\n",
    "    \"\"\"\n",
    "    Requests user input of a valid country from a predefined list of countries.\n",
    "    \n",
    "    Parameters:\n",
    "    prompt (str): A string to display as a prompt for the user input.\n",
    "    \n",
    "    Returns:\n",
    "    str: A valid country entered by the user.\n",
    "    \"\"\"\n",
    "\n",
    "    valid_countries = [\"United Kingdom\", \"Sweden\", \"Belgium\", \"Netherlands\", \"Germany\", \"Denmark\"]\n",
    "    while True:\n",
    "        country = input(prompt)\n",
    "        if country in valid_countries:\n",
    "            return country\n",
    "        else:\n",
    "            print(\"Invalid country. Please enter one of the following countries:\", ', '.join(valid_countries))\n",
    "\n",
    "\n",
    "## 1.4) Create function that requests  user input of minimum distance and maximum distance (to define range to look at)\n",
    "\n",
    "def get_distance_input(prompt):\n",
    "    \"\"\"\n",
    "    Requests user input for a distance and validates the input.\n",
    "    \n",
    "    Parameters:\n",
    "    prompt (str): The prompt to display when requesting user input.\n",
    "    \n",
    "    Returns:\n",
    "    float or str: A valid distance input as a float, or the string 'all' for no maximum distance.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            distance = input(prompt)\n",
    "            if distance == 'all':\n",
    "                return distance\n",
    "            distance = float(distance)\n",
    "            if distance >= 0:\n",
    "                return distance\n",
    "            else:\n",
    "                print(\"Invalid input. Distance must be greater than or equal to 0.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number or 'all'.\")\n",
    "\n",
    "\n",
    "\n",
    "## 1.5) Defining main() function  to be called to execute filtering of dataset\n",
    "\n",
    "def filter_and_export():\n",
    "    \n",
    "    \"\"\"\n",
    "    Interactively requests user input for country and distance range, filters a dataset based on the input, \n",
    "    and exports the filtered dataset as a CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get user inputs\n",
    "    country = get_country_input(\"Please enter a country (United Kingdom, Sweden, Belgium, Netherlands, Germany, Denmark): \")\n",
    "    min_distance = get_distance_input(\"Please enter a minimum distance (>= 0): \")\n",
    "    max_distance = get_distance_input(\"Please enter a maximum distance (>= minimum distance) or type 'all' for no maximum: \")\n",
    "\n",
    "    if max_distance == \"all\":\n",
    "        max_distance = None\n",
    "    else:\n",
    "        while float(max_distance) <= min_distance:\n",
    "            print(\"Maximum distance must be greater than the minimum distance.\")\n",
    "            max_distance = get_distance_input(\"Please enter a maximum distance (>= minimum distance) or type 'all' for no maximum: \")\n",
    "\n",
    "    # Filter the dataframe based on user inputs\n",
    "    filtered_df = filter_country_distance(df_routes, country, min_distance, max_distance)\n",
    "\n",
    "    # Export the filtered dataframe\n",
    "    if not os.path.exists(dataframes_dir):\n",
    "        os.makedirs(dataframes_dir)\n",
    "\n",
    "    if country == \"United Kingdom\":\n",
    "        country_abbr = \"UK\"\n",
    "    else:\n",
    "        country_abbr = country.replace(' ', '_')\n",
    "\n",
    "    if max_distance is None:\n",
    "        filtered_df_key = f\"df_routes_{country_abbr}_all\"\n",
    "    else:\n",
    "        max_distance_str = int(max_distance)\n",
    "        filtered_df_key = f\"df_routes_{country_abbr}_{int(min_distance)}_{max_distance_str}\"\n",
    "\n",
    "    export_filtered_dataframes({filtered_df_key: filtered_df}, dataframes_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame df_routes_Denmark_all already exists at /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/filtered_dataframes/df_routes_Denmark_all.csv.\n"
     ]
    }
   ],
   "source": [
    "# Calling main function to start filtering proceess\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "filter_and_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2) Building functions for Graph Building \n",
    "\n",
    "def build_graph(df_routes):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a directed graph object from the given dataframe of routes.\n",
    "    \n",
    "    Args:\n",
    "        df_routes (pandas.DataFrame): A dataframe containing columns 'FromLatitude', 'FromLongitude', 'ToLatitude',\n",
    "                                       'ToLongitude', and 'RouteCount', representing the routes between locations and the\n",
    "                                       number of times each route was taken.\n",
    "    \n",
    "    Returns:\n",
    "        G (networkx.DiGraph): A directed graph object representing the routes between locations, with edges weighted by\n",
    "                              the number of times each route was taken.\n",
    "    \"\"\"\n",
    "\n",
    "    if df_routes.empty or not all(col in df_routes.columns for col in ['FromLatitude', 'FromLongitude', 'ToLatitude', 'ToLongitude', 'RouteCount']):\n",
    "        raise ValueError(\"Input dataframe is empty or missing required columns.\")\n",
    "\n",
    "    # Creating empty graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes and edges to the graph\n",
    "    for idx, row in df_routes.iterrows():\n",
    "        from_node = (row['FromLatitude'], row['FromLongitude'])\n",
    "        to_node = (row['ToLatitude'], row['ToLongitude'])\n",
    "\n",
    "        if from_node not in G:\n",
    "            G.add_node(from_node, latitude=row['FromLatitude'], longitude=row['FromLongitude'])\n",
    "        if to_node not in G:\n",
    "            G.add_node(to_node, latitude=row['ToLatitude'], longitude=row['ToLongitude'])\n",
    "\n",
    "        G.add_edge(from_node, to_node, route_count=row['RouteCount'], route_distance=row['RouteDistance'])\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def calculate_node_traffic(graph):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the total traffic passing through each node in the given graph.\n",
    "    \n",
    "    Args:\n",
    "        graph (networkx.DiGraph): The graph object representing the routes between locations.\n",
    "    \n",
    "    Returns:\n",
    "        node_traffic (dict): A dictionary mapping node coordinates to the total traffic passing through them.\n",
    "    \"\"\"\n",
    "\n",
    "    node_traffic = {}\n",
    "\n",
    "    for edge in graph.edges(data=True):\n",
    "        start, end, data = edge\n",
    "        route_count = data['route_count'] \n",
    "\n",
    "        if start not in node_traffic:\n",
    "            node_traffic[start] = 0\n",
    "        if end not in node_traffic:\n",
    "            node_traffic[end] = 0\n",
    "\n",
    "        node_traffic[start] += route_count\n",
    "        node_traffic[end] += route_count\n",
    "\n",
    "    return node_traffic\n",
    "\n",
    "\n",
    "def normalize_node_traffic(node_traffic):\n",
    "\n",
    "    \"\"\"\n",
    "    Normalizes the traffic values for each node to the range [0, 1].\n",
    "    \n",
    "    Args:\n",
    "        node_traffic (dict): A dictionary mapping node coordinates to the total traffic passing through them.\n",
    "    \n",
    "    Returns:\n",
    "        node_traffic_normalized (dict): A dictionary mapping node coordinates to the normalized traffic values.\n",
    "    \"\"\"\n",
    "\n",
    "    max_node_traffic = max(node_traffic.values())\n",
    "    return {node: math.log(traffic + 1) / math.log(max_node_traffic + 1) for node, traffic in node_traffic.items()}\n",
    "\n",
    "\n",
    "def create_map(df_routes, graph, node_traffic_normalized):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates a Folium map object displaying the nodes and edges of the given graph, with node sizes and edge colors\n",
    "    scaled according to the normalized traffic values.\n",
    "    \n",
    "    Args:\n",
    "        df_routes (pandas.DataFrame): A dataframe containing columns 'FromLatitude' and 'FromLongitude', representing the\n",
    "                                       locations of the nodes in the graph.\n",
    "        graph (networkx.DiGraph): The graph object representing the routes between locations.\n",
    "        node_traffic_normalized (dict): A dictionary mapping node coordinates to the normalized traffic values.\n",
    "    \n",
    "    Returns:\n",
    "        folium_map (folium.folium.Map): A Folium map object displaying the nodes and edges of the graph.\n",
    "    \"\"\"\n",
    "\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        raise ValueError(\"Input graph has no nodes.\")\n",
    "\n",
    "    # Calculate the map center using the average latitude and longitude of all nodes\n",
    "    map_center = [sum(coord[0] for coord in graph.nodes()) / graph.number_of_nodes(),\n",
    "                  sum(coord[1] for coord in graph.nodes()) / graph.number_of_nodes()]\n",
    "\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=5, tiles='CartoDB Positron')\n",
    "    add_nodes_edges_to_map(graph, folium_map, node_traffic_normalized)\n",
    "    return folium_map\n",
    "\n",
    "\n",
    "def add_nodes_edges_to_map(graph, folium_map, node_traffic_normalized):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds the nodes and edges of the given graph to the given Folium map object, with node sizes and edge colors\n",
    "    scaled according to the normalized traffic values.\n",
    "    \n",
    "    Args:\n",
    "        graph (networkx.DiGraph): The graph object representing the routes between locations.\n",
    "        folium_map (folium.folium.Map): The Folium map object to which the nodes and edges should be added.\n",
    "        node_traffic_normalized (dict): A dictionary mapping node coordinates to the normalized traffic values.\n",
    "    \"\"\"\n",
    "\n",
    "    max_route_count = max(data['route_count'] for _, _, data in graph.edges(data=True))\n",
    "\n",
    "    for edge in graph.edges(data=True):\n",
    "        start, end, data = edge\n",
    "\n",
    "        start_intensity = node_traffic_normalized[start]\n",
    "        end_intensity = node_traffic_normalized[end]\n",
    "\n",
    "        start_color = matplotlib.colors.to_hex(plt.cm.get_cmap('Blues')(start_intensity))\n",
    "        end_color = matplotlib.colors.to_hex(plt.cm.get_cmap('Blues')(end_intensity))\n",
    "\n",
    "        start_node_marker = CircleMarker(location=start, radius=0.5, color=start_color, fill=True, fill_opacity=0.5)\n",
    "        end_node_marker = CircleMarker(location=end, radius=0.5, color=end_color, fill=True, fill_opacity=0.5)\n",
    "\n",
    "        intensity = math.log(data['route_count'] + 1) / math.log(max_route_count + 1)\n",
    "        edge_color = matplotlib.colors.to_hex(plt.cm.get_cmap('coolwarm')(intensity))\n",
    "\n",
    "        polyline = PolyLine(locations=[start, end], color=edge_color, weight=1)\n",
    "\n",
    "        folium_map.add_child(start_node_marker)\n",
    "        folium_map.add_child(end_node_marker)\n",
    "        folium_map.add_child(polyline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved for Denmark_None_None: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/graphs/G_Denmark_all.graphml\n",
      "Map saved for Denmark_None_None: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_map_all_routes.html\n",
      "Graph saved for Belgium_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/graphs/G_Belgium_5_300.graphml\n",
      "Map saved for Belgium_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_map_all_routes_5_300.html\n",
      "Graph saved for Denmark_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/graphs/G_Denmark_5_300.graphml\n",
      "Map saved for Denmark_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_map_all_routes_5_300.html\n",
      "Graph saved for Belgium_None_None: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/graphs/G_Belgium_all.graphml\n",
      "Map saved for Belgium_None_None: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_map_all_routes.html\n"
     ]
    }
   ],
   "source": [
    "### 3) Creating graphs and respective maps for all the created dataframes in step 1) by using the functions defined in step 2)\n",
    "\n",
    "# Find all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(dataframes_dir, 'df_routes_*.csv'))\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # Load the DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract country, min_distance, and max_distance from the file name\n",
    "    file_name = os.path.basename(csv_file)[:-4]  # Remove the .csv extension\n",
    "    file_name_parts = file_name.split('_')\n",
    "\n",
    "    if file_name_parts[-1] == \"all\":\n",
    "        max_distance = None\n",
    "        min_distance = None\n",
    "        country = '_'.join(file_name_parts[2:-1])  # Rejoin the country name parts\n",
    "    else:\n",
    "        min_distance = file_name_parts[-2]\n",
    "        max_distance = file_name_parts[-1]\n",
    "        country = '_'.join(file_name_parts[2:-2])  # Rejoin the country name parts\n",
    "\n",
    "    # Build the graph and calculate node traffic\n",
    "    graph = build_graph(df)\n",
    "    node_traffic = calculate_node_traffic(graph)\n",
    "    node_traffic_normalized = normalize_node_traffic(node_traffic)\n",
    "\n",
    "    # Save the graph to a GraphML file and export to directory\n",
    "    if max_distance is None:\n",
    "        graph_name = f'G_{country}_all.graphml'\n",
    "    else:\n",
    "        graph_name = f'G_{country}_{min_distance}_{max_distance}.graphml'\n",
    "    graph_path = os.path.join(graphs_dir, graph_name)\n",
    "    nx.write_graphml(graph, graph_path)\n",
    "    \n",
    "    print(f\"Graph saved for {country}_{min_distance}_{max_distance}: {graph_path}\")\n",
    "\n",
    "    # Create and save the map\n",
    "    map_all = create_map(df, graph, node_traffic_normalized)\n",
    "    if max_distance is None:\n",
    "        map_name = f'{country}_map_all_routes.html'\n",
    "    else:\n",
    "        map_name = f'{country}_map_all_routes_{min_distance}_{max_distance}.html'\n",
    "    map_path = os.path.join(maps_dir, map_name)\n",
    "    map_all.save(map_path)\n",
    "\n",
    "    print(f\"Map saved for {country}_{min_distance}_{max_distance}: {map_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_routes(graphs_dir, maps_dir):\n",
    "    \n",
    "    \"\"\"\n",
    "    Visualizes the top 2.5% most used routes and their attached nodes for each country's graph in the specified directory, where each graph's name follows the format 'G_{country}_all.graphml'.\n",
    "    \n",
    "    Parameters:\n",
    "    graphs_dir (str): The directory where the graphs for each country are stored in GraphML format.\n",
    "    maps_dir (str): The directory where the generated folium maps will be saved in HTML format.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    top_routes_dict = {}\n",
    "    \n",
    "    # Get the graph name and split it into components\n",
    "    file = graph.name\n",
    "    components = file.split(\"_\")\n",
    "\n",
    "    # Extract the country, min_distance, and max_distance from the components\n",
    "    country = components[1]\n",
    "    if len(components) == 4:\n",
    "        min_distance, max_distance = components[2:4]\n",
    "        max_distance = max_distance.split(\".\")[0]\n",
    "    else:\n",
    "        min_distance, max_distance = \"all\", \"all\"\n",
    "\n",
    "    # Get the edge weights and sort them in descending order\n",
    "    edges_weights = [(u, v, data[\"route_count\"], data[\"route_distance\"]) for u, v, data in graph.edges(data=True)]\n",
    "    edges_weights.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Filter the top 2.5% of edges\n",
    "    n_top_edges = int(0.025 * len(edges_weights))\n",
    "    top_edges = edges_weights[:n_top_edges]\n",
    "\n",
    "    # Store the top edges in the dictionary\n",
    "    top_routes_dict[country] = top_edges\n",
    "\n",
    "    # Create a folium map centered at the first node's coordinates\n",
    "    first_node = graph.nodes[top_edges[0][0]]\n",
    "    m = Map(location=[first_node[\"latitude\"], first_node[\"longitude\"]], zoom_start=5, tiles='CartoDB Positron')\n",
    "\n",
    "    # Normalize the weights for color mapping\n",
    "    max_weight = top_edges[0][2]\n",
    "    min_weight = top_edges[-1][2]\n",
    "\n",
    "    def normalize_weight(weight):\n",
    "        normalized_weight = (weight - min_weight) / (max_weight - min_weight)\n",
    "        normalized_weight = max(0, normalized_weight)  # Ensure the value is non-negative\n",
    "        #print(f\"[visualize_top_routes] weight: {weight}, min_weight: {min_weight}, max_weight: {max_weight}, normalized_weight: {normalized_weight}\")\n",
    "        return normalized_weight ** 0.5\n",
    "\n",
    "    # Add the top routes to the map\n",
    "    for u, v, weight, _ in reversed(top_edges):  # Reverse the order in which routes are added to the map\n",
    "        node_u = graph.nodes[u]\n",
    "        node_v = graph.nodes[v]\n",
    "\n",
    "        coordinates = [\n",
    "            [node_u[\"latitude\"], node_u[\"longitude\"]],\n",
    "            [node_v[\"latitude\"], node_v[\"longitude\"]],\n",
    "        ]\n",
    "\n",
    "        # Color code the edges using a warm-cold colormap\n",
    "        edge_color = plt.cm.coolwarm(normalize_weight(weight))\n",
    "\n",
    "        # Convert the color to a hex format\n",
    "        edge_color_hex = \"#{:02x}{:02x}{:02x}\".format(*(int(255 * c) for c in edge_color[:3]))\n",
    "\n",
    "        # Calculate the weight of the polyline based on the route count\n",
    "        route_weight = 0.5 + 2 * normalize_weight(weight)\n",
    "\n",
    "        # Add the route to the map\n",
    "        polyline = PolyLine(\n",
    "            locations=coordinates,\n",
    "            color=edge_color_hex,\n",
    "            weight=route_weight,\n",
    "            opacity=1,\n",
    "        )\n",
    "        m.add_child(polyline)\n",
    "\n",
    "    # Save the map to the maps directory\n",
    "    map_path = os.path.join(maps_dir, f\"{country}_map_top_routes_{min_distance}_{max_distance}.html\")\n",
    "    m.save(map_path)\n",
    "    print(f\"Map with Top 2.5% most used routes saved for {country}_{min_distance}_{max_distance}: {map_path}\")\n",
    "\n",
    "    # Return dictionary with top 2.5% used routes\n",
    "    return top_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map with Top 2.5% most used routes saved for Belgium_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_map_top_routes_5_300.html\n",
      "Map with Top 2.5% most used routes saved for Denmark_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_map_top_routes_5_300.html\n"
     ]
    }
   ],
   "source": [
    "top_routes_dict = {}\n",
    "\n",
    "for file in os.listdir(graphs_dir):\n",
    "    if file.endswith(\"_all.graphml\") or not file.endswith(\".graphml\"):\n",
    "        continue\n",
    "\n",
    "    graph_file = os.path.join(graphs_dir, file)\n",
    "    graph = nx.read_graphml(graph_file)\n",
    "    graph.name = file\n",
    "\n",
    "    top_edges = visualize_top_routes(graph, maps_dir)\n",
    "    \n",
    "    # Get the graph name and split it into components\n",
    "    components = file.split(\"_\")\n",
    "    country = components[1]\n",
    "    if len(components) == 4:\n",
    "        min_distance, max_distance = components[2:4]\n",
    "        max_distance = max_distance.split(\".\")[0]\n",
    "    else:\n",
    "        min_distance, max_distance = \"all\", \"all\"\n",
    "        \n",
    "    top_routes_dict[f\"{country}_{min_distance}_{max_distance}\"] = top_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_communities(graph):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates communities in the input graph using the Louvain algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    \n",
    "    Returns:\n",
    "    dict: The partition of the graph's nodes into communities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the directed graph to an undirected graph\n",
    "    graph_undirected = graph.to_undirected()\n",
    "\n",
    "    # Calculate communities using the Louvain algorithm on the undirected graph\n",
    "    partition = community_louvain.best_partition(graph_undirected)\n",
    "\n",
    "    # Return the partition for later use\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get 3 biggest communities for the Graph and visualize\n",
    "\n",
    "def visualize_top_communities(graph, partition, maps_dir):\n",
    "    \"\"\"\n",
    "    Visualizes the three biggest communities in the input graph on a map, based on the given partition.\n",
    "    \n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    partition (dict): The partition of the graph's nodes into communities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract min_distance and max_distance from the graph name\n",
    "    graph_name_no_ext = os.path.splitext(graph.name)[0]\n",
    "    country, min_distance, max_distance = graph_name_no_ext.split(\"_\")[1:4]\n",
    "    max_distance = max_distance.split(\".\")[0]\n",
    "\n",
    "    # Get the top 3 largest communities\n",
    "    community_counts = Counter(partition.values())\n",
    "    largest_communities = [community for community, _ in community_counts.most_common(3)]\n",
    "\n",
    "    # Assign unique colors to each community\n",
    "    community_colors = {\n",
    "        largest_communities[0]: np.array([0, 0, 0.7]),  # dark blue\n",
    "        largest_communities[1]: np.array([0, 0.5, 1]),    # regular blue\n",
    "        largest_communities[2]: np.array([0.7, 0.85, 1]) # light blue\n",
    "    }\n",
    "    \n",
    "    # Calculate the map center using the average latitude and longitude of all nodes\n",
    "    map_center = [sum(graph.nodes[node]['latitude'] for node in graph.nodes()) / graph.number_of_nodes(),\n",
    "                  sum(graph.nodes[node]['longitude'] for node in graph.nodes()) / graph.number_of_nodes()]\n",
    "\n",
    "    # Create a folium map for visualization\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=5, tiles='CartoDB Positron')\n",
    "\n",
    "    # Add nodes to the folium map with colors based on their community (only for the largest communities)\n",
    "    for node, community in partition.items():\n",
    "        if community in largest_communities:\n",
    "            marker = folium.CircleMarker(location=[graph.nodes[node]['latitude'], graph.nodes[node]['longitude']],\n",
    "                                         radius=5,\n",
    "                                         color=matplotlib.colors.to_hex(community_colors[community]),\n",
    "                                         fill=True,\n",
    "                                         fill_opacity=1)\n",
    "            folium_map.add_child(marker)\n",
    "\n",
    "    # Save the map as an HTML file\n",
    "    html_filename = f\"{country}_communities_top3_{min_distance}_{max_distance}.html\"\n",
    "    map_path = os.path.join(maps_dir, html_filename)\n",
    "    folium_map.save(map_path)\n",
    "\n",
    "    print(f\"Top 3 Communities map for {country}_{min_distance}_{max_distance} saved as {map_path}\")\n",
    "    \n",
    "    # Return the partition of the top 3 communities\n",
    "    top_communities_partition = {node: community for node, community in partition.items() if community in largest_communities}\n",
    "    \n",
    "    return top_communities_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_visualize_top_nodes(graph, top_communities_partition, save_outputs = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the top nodes for each of the top 3 communities in the input graph based on node traffic and centrality measures.\n",
    "    Visualizes the top nodes on a map using Folium, and saves the node information in an HTML table.\n",
    "\n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    top_communities_partition (dict): A dictionary that maps each top node to its community label.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of the top 15 nodes across all top communities, sorted by node traffic in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Remove the file extension from the graph name\n",
    "    graph_name_no_ext = os.path.splitext(graph.name)[0]\n",
    "\n",
    "    # Extract country, min_distance, and max_distance from the graph name\n",
    "    country, min_distance, max_distance = graph_name_no_ext.split(\"_\")[1:4]\n",
    "    max_distance = max_distance.split(\".\")[0]\n",
    "\n",
    "\n",
    "    # Calculate node traffic\n",
    "    node_traffic = calculate_node_traffic(graph)\n",
    "\n",
    "    # Get top 3 communities from the partition\n",
    "    top_communities = [comm for comm, _ in Counter(top_communities_partition.values()).most_common(3)]\n",
    "\n",
    "    # Get top 5 nodes by total traffic for each of the top 3 communities\n",
    "    top_nodes = []\n",
    "    for community in top_communities:\n",
    "        community_nodes = [node for node, comm in top_communities_partition.items() if comm == community]\n",
    "        community_node_traffic = {node: node_traffic[node] for node in community_nodes}\n",
    "        top_community_nodes = sorted(community_node_traffic, key=community_node_traffic.get, reverse=True)[:5]\n",
    "        top_nodes.extend(top_community_nodes)\n",
    "\n",
    "    # Calculate weighted centrality measures for the top nodes\n",
    "    node_data = []\n",
    "\n",
    "    for node in top_nodes:\n",
    "        weight_func = lambda u, v, d: d['route_count']\n",
    "        betweenness_centrality = nx.betweenness_centrality(graph, weight=weight_func)[node]\n",
    "        # eigenvector_centrality = nx.eigenvector_centrality(graph, weight='route_count', max_iter=2500)[node]\n",
    "        degree_centrality = nx.degree_centrality(graph)[node]\n",
    "\n",
    "        node_data.append((node, betweenness_centrality, degree_centrality))\n",
    "\n",
    "\n",
    "    # Sort the node data by node traffic in descending order\n",
    "    sorted_node_data = sorted(node_data, key=lambda x: node_traffic[x[0]], reverse=True)\n",
    "\n",
    "    if save_outputs:\n",
    "        # Visualization\n",
    "        # Calculate the map center using the average latitude and longitude of all nodes\n",
    "        map_center = [sum(graph.nodes[node]['latitude'] for node in graph.nodes()) / graph.number_of_nodes(),\n",
    "                    sum(graph.nodes[node]['longitude'] for node in graph.nodes()) / graph.number_of_nodes()]\n",
    "\n",
    "        # Create a folium map for visualization\n",
    "        folium_map = folium.Map(location=map_center, zoom_start=5, tiles='CartoDB Positron')\n",
    "\n",
    "        # Assign unique colors to each community\n",
    "        community_colors = {\n",
    "            top_communities[0]: np.array([0, 0, 0.7]),  # dark blue\n",
    "            top_communities[1]: np.array([0, 0.5, 1]),    # regular blue\n",
    "            top_communities[2]: np.array([0.7, 0.85, 1]) # light blue\n",
    "        }\n",
    "\n",
    "        # Add top nodes to the folium map with colors based on their community\n",
    "        for node, betweenness_centrality, degree_centrality in sorted_node_data:\n",
    "            community = top_communities_partition[node]\n",
    "            marker = folium.CircleMarker(location=[graph.nodes[node]['latitude'], graph.nodes[node]['longitude']],\n",
    "                                        radius=7,\n",
    "                                        color=matplotlib.colors.to_hex(community_colors[community]),\n",
    "                                        fill=True,\n",
    "                                        fill_opacity=1)\n",
    "            folium_map.add_child(marker)\n",
    "\n",
    "        # Save the map as an HTML file\n",
    "        html_filename = f\"{country}_top_nodes_{min_distance}_{max_distance}.html\"\n",
    "        print_message = f\"Top 15 nodes map for {country}, min_distance: {min_distance}, max_distance: {max_distance} saved as \"\n",
    "\n",
    "        map_path = os.path.join(maps_dir, html_filename)\n",
    "        folium_map.save(map_path)\n",
    "\n",
    "        print(print_message + map_path) \n",
    "\n",
    "\n",
    "        # Generate an HTML string with the desired table format\n",
    "        html_string = \"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "        <style>\n",
    "            table {{\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "            }}\n",
    "            th, td {{\n",
    "                text-align: left;\n",
    "                padding: 8px;\n",
    "                border-bottom: 1px solid #ddd;\n",
    "            }}\n",
    "            th {{\n",
    "                background-color: #f2f2f2;\n",
    "            }}\n",
    "        </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h1>Top Nodes for {graph_name}</h1>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Node</th>\n",
    "                <th>Node Traffic</th>\n",
    "                <th>Weighted Betweenness Centrality</th>\n",
    "                <th>Weighted Degree Centrality</th>\n",
    "            </tr>\n",
    "        \"\"\".format(graph_name=graph.name)\n",
    "\n",
    "        for node, betweenness_centrality, degree_centrality in sorted_node_data:\n",
    "            html_string += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{node}</td>\n",
    "                <td>{node_traffic[node]}</td>\n",
    "                <td>{betweenness_centrality}</td>\n",
    "                <td>{degree_centrality}</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "\n",
    "        html_string += \"\"\"\n",
    "        </table>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Save the HTML string to a file\n",
    "        file_name = f\"{graph.name}_top_nodes_info.html\"\n",
    "        file_path = os.path.join(info_dir, file_name)\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(html_string)\n",
    "\n",
    "        # Print a confirmation message\n",
    "        print(f\"Node information for {graph.name} saved as {file_path}\")\n",
    "\n",
    "    # Return the top_nodes list for next step\n",
    "    return top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Communities map for Belgium_5_300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_communities_top3_5_300.html\n",
      "Top 15 nodes map for Belgium, min_distance: 5, max_distance: 300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_top_nodes_5_300.html\n",
      "Node information for G_Belgium_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Belgium_5_300.graphml_top_nodes_info.html\n",
      "Top 3 Communities map for Denmark_5_300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_communities_top3_5_300.html\n",
      "Top 15 nodes map for Denmark, min_distance: 5, max_distance: 300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_top_nodes_5_300.html\n",
      "Node information for G_Denmark_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Denmark_5_300.graphml_top_nodes_info.html\n"
     ]
    }
   ],
   "source": [
    "# Now calling the functions defined above\n",
    "\n",
    "# Iterate through the graph files in the graphs_dir directory\n",
    "for file in os.listdir(graphs_dir):\n",
    "    if file.endswith(\".graphml\") and not file.endswith(\"_all.graphml\"):\n",
    "        graph_file = os.path.join(graphs_dir, file)\n",
    "        graph = nx.read_graphml(graph_file)\n",
    "        graph.name = file  # Set the graph.name attribute explicitly\n",
    "\n",
    "        # Calling two functions on community detection\n",
    "        partition = calculate_communities(graph)\n",
    "        top_communities_partition = visualize_top_communities(graph, partition, maps_dir)\n",
    "\n",
    "        # Call the calculate_visualize_top_nodes function\n",
    "        top_nodes = calculate_visualize_top_nodes(graph, top_communities_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_top_routes_and_nodes(graph, top_nodes, top_routes, maps_dir):\n",
    "    \"\"\"\n",
    "    Compares the routes attached to the top nodes with the top most important routes, creates a list of overlapping routes,\n",
    "    and calculates the share of the top routes that are attached to at least one of the top nodes.\n",
    "\n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    top_nodes (list): List of top 15 nodes based on node traffic\n",
    "    top_routes (list): List of the most important routes in the graph.\n",
    "    maps_dir (str): The directory where the generated folium maps will be saved in HTML format.\n",
    "\n",
    "    Returns:\n",
    "    overlap_routes (list): List of routes that are both part of the most important routes and attached to at least one of the top nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify routes attached to the top nodes\n",
    "    routes_attached_to_top_nodes = []\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if u in top_nodes or v in top_nodes:\n",
    "            routes_attached_to_top_nodes.append((u, v, data))\n",
    "\n",
    "    # Compare routes_attached_to_top_nodes with top_routes\n",
    "    top_route_edges = {(u, v) for u, v, route_count, route_distance in top_routes}\n",
    "\n",
    "    overlap_routes = []\n",
    "    for u, v, data in routes_attached_to_top_nodes:\n",
    "        for tr_u, tr_v, tr_data, _ in top_routes:\n",
    "            if (u == tr_u and v == tr_v) or (u == tr_v and v == tr_u):\n",
    "                overlap_routes.append((u, v, data))\n",
    "                break\n",
    "\n",
    "    # Calculate the share of the top routes that are attached to at least one of the top nodes\n",
    "    electrifiable_share = (len(overlap_routes) / len(top_routes)) * 100\n",
    "\n",
    "    # Print result\n",
    "    print(f\"Electrifiable share of most important routes: {electrifiable_share}%\")\n",
    "\n",
    "    return overlap_routes, electrifiable_share, routes_attached_to_top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlap(graph, top_routes, overlap_routes, maps_dir):\n",
    "    \"\"\"\n",
    "    Visualizes the overlapping routes between the top 2.5% most used routes and routes attached to the top nodes.\n",
    "\n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    top_routes (list): List of top 2.5% most used routes.\n",
    "    overlap_routes (list): List of routes that are both part of the top 2.5% most used routes and attached to at least one of the top nodes.\n",
    "    maps_dir (str): The directory where the generated folium maps will be saved in HTML format.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a folium map centered at the first node's coordinates\n",
    "    first_node = graph.nodes[top_routes[0][0]]\n",
    "    m = folium.Map(location=[first_node['latitude'], first_node['longitude']], zoom_start=5, tiles='CartoDB Positron')\n",
    "\n",
    "    # Normalize the weights for color mapping\n",
    "    max_weight = max(data['route_count'] for _, _, data in overlap_routes)\n",
    "    min_weight = min(data['route_count'] for _, _, data in overlap_routes)\n",
    "\n",
    "\n",
    "    def normalize_weight(weight):\n",
    "        normalized_weight = (weight - min_weight) / (max_weight - min_weight)\n",
    "        normalized_weight = max(0, normalized_weight)  # Ensure the value is non-negative\n",
    "        return normalized_weight ** 0.5\n",
    "\n",
    "    # Add the overlapping routes to the map\n",
    "    for u, v, data in overlap_routes:\n",
    "        node_u = graph.nodes[u]\n",
    "        node_v = graph.nodes[v]\n",
    "\n",
    "        coordinates = [\n",
    "            [node_u['latitude'], node_u['longitude']],\n",
    "            [node_v['latitude'], node_v['longitude']],\n",
    "        ]\n",
    "\n",
    "        # Color code the edges using a warm-cold colormap\n",
    "        edge_color = plt.cm.coolwarm(normalize_weight(data['route_count']))\n",
    "\n",
    "        # Convert the color to a hex format\n",
    "        edge_color_hex = \"#{:02x}{:02x}{:02x}\".format(*(int(255 * c) for c in edge_color[:3]))\n",
    "\n",
    "        # Calculate the weight of the polyline based on the route count\n",
    "        route_weight = 0.5 + 2 * normalize_weight(data['route_count'])\n",
    "\n",
    "        # Add the route to the map\n",
    "        polyline = folium.PolyLine(\n",
    "            locations=coordinates,\n",
    "            color=edge_color_hex,\n",
    "            weight=route_weight,\n",
    "            opacity=1,\n",
    "        )\n",
    "        m.add_child(polyline)\n",
    "\n",
    "    # Save the map to the maps directory\n",
    "    map_path = os.path.join(maps_dir, f\"{country}_overlap_top_routes_{min_distance}_{max_distance}.html\")\n",
    "    m.save(map_path)\n",
    "    print(f\"Overlap routes map saved for {country}_{min_distance}_{max_distance}: {map_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Communities map for Belgium_5_300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_communities_top3_5_300.html\n",
      "Top 15 nodes map for Belgium, min_distance: 5, max_distance: 300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_top_nodes_5_300.html\n",
      "Node information for G_Belgium_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Belgium_5_300.graphml_top_nodes_info.html\n",
      "Electrifiable share of most important routes: 91.17647058823529%\n",
      "Overlap routes map saved for Belgium_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Belgium_overlap_top_routes_5_300.html\n",
      "Top 3 Communities map for Denmark_5_300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_communities_top3_5_300.html\n",
      "Top 15 nodes map for Denmark, min_distance: 5, max_distance: 300 saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_top_nodes_5_300.html\n",
      "Node information for G_Denmark_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Denmark_5_300.graphml_top_nodes_info.html\n",
      "Electrifiable share of most important routes: 67.81609195402298%\n",
      "Overlap routes map saved for Denmark_5_300: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/maps/Denmark_overlap_top_routes_5_300.html\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store electrifiable_share for each graph\n",
    "electrifiable_share_dict = {}\n",
    "\n",
    "# Loop through the directory and find graphs with the '_{min_distance}_{max_distance}.graphml' format\n",
    "for file in os.listdir(graphs_dir):\n",
    "    if \"_all.graphml\" in file or not file.endswith(\".graphml\"):\n",
    "        continue\n",
    "\n",
    "    country, min_distance, max_distance = file.split(\"_\")[1:4]\n",
    "    max_distance = max_distance.split(\".\")[0]\n",
    "\n",
    "    # Read the graph\n",
    "    graph_file = os.path.join(graphs_dir, file)\n",
    "    graph = nx.read_graphml(graph_file)\n",
    "    graph.name = file  # Set the graph.name attribute explicitly\n",
    "\n",
    "    # Calculate the communities and top communities partition for the graph\n",
    "    partition = calculate_communities(graph)\n",
    "    top_communities_partition = visualize_top_communities(graph, partition, maps_dir)\n",
    "\n",
    "    # Calculate the top 15 nodes for the graph\n",
    "    top_nodes = calculate_visualize_top_nodes(graph, top_communities_partition)\n",
    "\n",
    "    # Get the top 2.5% most used routes for the graph\n",
    "    top_routes = top_routes_dict[f\"{country}_{min_distance}_{max_distance}\"]\n",
    "\n",
    "    # Compare the routes attached to the top nodes with the top 2.5% of routes\n",
    "    overlap_routes, electrifiable_share, routes_attached_to_top_nodes = compare_top_routes_and_nodes(graph, top_nodes, top_routes, maps_dir)\n",
    "\n",
    "    # Add the electrifiable_share to the dictionary\n",
    "    electrifiable_share_dict[graph.name] = electrifiable_share\n",
    "\n",
    "    # Visualize the overlapping routes\n",
    "    visualize_overlap(graph, top_routes, overlap_routes, maps_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'G_Belgium_5_300.graphml': 91.17647058823529, 'G_Denmark_5_300.graphml': 67.81609195402298}\n",
      "Electrifiable share dictionary saved as an HTML file: /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/electrifiable_share_all_countries.html\n"
     ]
    }
   ],
   "source": [
    "# Print the electrifiable_share_dict\n",
    "print(electrifiable_share_dict)\n",
    "\n",
    "# Function to convert the dictionary to an HTML table\n",
    "def dict_to_html_table(dictionary):\n",
    "    html_table = \"<table border='1'>\"\n",
    "    html_table += \"<tr><th>Graph Name</th><th>Electrifiable Share</th></tr>\"\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        html_table += f\"<tr><td>{key}</td><td>{value}</td></tr>\"\n",
    "    \n",
    "    html_table += \"</table>\"\n",
    "    return html_table\n",
    "\n",
    "\n",
    "# Convert the electrifiable_share_dict to an HTML table\n",
    "html_table = dict_to_html_table(electrifiable_share_dict)\n",
    "\n",
    "# Save the HTML table to a file\n",
    "os.makedirs(info_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "html_file_path = os.path.join(info_dir, \"electrifiable_share_all_countries.html\")\n",
    "\n",
    "with open(html_file_path, \"w\") as html_file:\n",
    "    html_file.write(html_table)\n",
    "\n",
    "print(f\"Electrifiable share dictionary saved as an HTML file: {html_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4) Create function to get info about Graph and communities\n",
    "\n",
    "def graph_community_info(graph, partition):\n",
    "\n",
    "    \"\"\"\n",
    "    Prints various community-related information for the input graph, such as the number of nodes and edges, \n",
    "    modularity, and top communities based on size and conductance.\n",
    "    \n",
    "    Parameters:\n",
    "    graph (networkx.Graph): The input graph with nodes representing locations and edges representing routes.\n",
    "    partition (dict): The partition of the graph's nodes into communities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of nodes and edges in the graph\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "\n",
    "    # Number of communities and modularity\n",
    "    num_communities = len(set(partition.values()))\n",
    "    modularity = community_louvain.modularity(partition, graph.to_undirected())\n",
    "\n",
    "    # Top 3 largest communities\n",
    "    community_counts = Counter(partition.values())\n",
    "    largest_communities = community_counts.most_common(3)\n",
    "\n",
    "    # Calculate the conductance for each of the largest communities\n",
    "    community_nodes = {comm: set() for comm, _ in largest_communities}\n",
    "    for node, community in partition.items():\n",
    "        if community in community_nodes:\n",
    "            community_nodes[community].add(node)\n",
    "\n",
    "    community_conductance = {}\n",
    "    for community, nodes in community_nodes.items():\n",
    "        community_boundary = list(nx.edge_boundary(graph, nodes))\n",
    "        community_conductance[community] = len(community_boundary) / len(nodes)\n",
    "\n",
    "    # Top 3 communities with the lowest conductance score (from the largest communities)\n",
    "    lowest_conductance_communities = sorted(community_conductance.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "    # Calculate avg. Degree of nodes \n",
    "    avg_degree = sum(d for _, d in graph.degree()) / float(num_nodes)\n",
    "\n",
    "    # Average clustering coefficient\n",
    "    avg_clustering_coeff = nx.average_clustering(graph)\n",
    "\n",
    "    # Create an HTML string for storing the information\n",
    "    html_string = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Graph Information</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>{graph.name} Information</h1>\n",
    "        <p>Number of nodes: {graph.number_of_nodes()}</p>\n",
    "        <p>Number of edges: {graph.number_of_edges()}</p>\n",
    "        <p>Average degree: {avg_degree:.4f}</p>\n",
    "        <p>Average clustering coefficient: {avg_clustering_coeff:.4f}</p>\n",
    "        <p>Number of communities: {num_communities}</p>\n",
    "        <p>Modularity of the community structure: {modularity:.4f}</p>\n",
    "        <h2>Top 3 largest communities:</h2>\n",
    "        <ol>\n",
    "            {\"\".join([f\"<li>Community {comm}: {size} nodes</li>\" for comm, size in largest_communities])}\n",
    "        </ol>\n",
    "        <h2>Conductance score for the largest communities:</h2>\n",
    "        <ol>\n",
    "            {\"\".join([f\"<li>Community {comm}: {score:.4f}</li>\" for comm, score in lowest_conductance_communities])}\n",
    "        </ol>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Save the HTML string to a file\n",
    "    file_name = f\"{graph.name}_info.html\"\n",
    "    file_path = os.path.join(info_dir, file_name)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(html_string)\n",
    "\n",
    "\n",
    "    # Print a confirmation message\n",
    "    print(f\"Graph information for {graph.name} saved as {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph information for G_Belgium_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Belgium_5_300.graphml_info.html\n",
      "Graph information for G_Denmark_5_300.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Denmark_5_300.graphml_info.html\n",
      "Graph information for G_Belgium_all.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Belgium_all.graphml_info.html\n",
      "Graph information for G_Denmark_all.graphml saved as /Users/jangaydoul/Desktop/Copenhagen Business School/4. Semester :: Thesis/03_Data/info/G_Denmark_all.graphml_info.html\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all graph files in the graphs_dir directory\n",
    "for file in os.listdir(graphs_dir):\n",
    "    if not file.endswith(\".graphml\"):\n",
    "        continue\n",
    "\n",
    "    # Read the graph from the file\n",
    "    graph_file = os.path.join(graphs_dir, file)\n",
    "    graph = nx.read_graphml(graph_file)\n",
    "    graph.name = file  # Set the graph.name attribute explicitly\n",
    "\n",
    "    # Calculate the communities for the graph using the Louvain algorithm\n",
    "    partition = calculate_communities(graph)\n",
    "\n",
    "    # Call the graph_community_info function\n",
    "    graph_community_info(graph, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5) Create function to compare the top nodes among different countries and distance ranges\n",
    "\n",
    "def top_nodes_comparison():\n",
    "  top_nodes_dict = {}\n",
    "  # Iterate through all files in the info_dir\n",
    "  for file_name in os.listdir(info_dir):\n",
    "    # Ignore files ending with '_all.graphml' and hidden files (starting with '.')\n",
    "    if file_name.endswith('graphml_top_nodes_info.html'):\n",
    "      #print(f\"Processing file: {file_name}\")  # Print the current file being processed\n",
    "      # Get main information for the file being processed\n",
    "      country, min_distance, max_distance = file_name.split(\"_\")[1:4]\n",
    "      max_distance = max_distance.split(\".\")[0]\n",
    "      html_file_name = f\"G_{country}_{min_distance}_{max_distance}.graphml_top_nodes_info.html\"\n",
    "    \n",
    "      # Find the corresponding HTML file and extract the top nodes\n",
    "      with open(os.path.join(info_dir, html_file_name), \"r\") as html_file:\n",
    "        soup = BeautifulSoup(html_file.read(), \"html.parser\")\n",
    "        top_nodes_table = soup.find(\"table\")\n",
    "        top_nodes = []\n",
    "        for row in top_nodes_table.findAll(\"tr\")[1:]:\n",
    "          cell = row.findAll(\"td\")[0]\n",
    "          node_coordinates = tuple(map(float, re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cell.text)))\n",
    "          top_nodes.append(node_coordinates)\n",
    "\n",
    "      # Store iformation about top nodes for each country and range in a dictionary\n",
    "      top_nodes_dict[f\"G_{country}_{min_distance}_{max_distance}\"]=top_nodes\n",
    "\n",
    "  # Generate a dataframe from the dictionary values\n",
    "  df=pd.DataFrame.from_dict(top_nodes_dict)\n",
    "  return top_nodes_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function above \n",
    "\n",
    "top_nodes_dict,top_nodes_df=top_nodes_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the dataframe\n",
    "top_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6) Create function to find common nodes between the different scenarios for each country\n",
    "\n",
    "def get_node_comparison_by_country(top_nodes_dict):\n",
    "  countries = [\"UK\", \"Sweden\", \"Belgium\", \"Netherlands\", \"Germany\", \"Denmark\"]\n",
    "  common_nodes={}\n",
    "\n",
    "  # Iterate through each country\n",
    "  for country in countries:\n",
    "    shared=[]\n",
    "    common_positions={}\n",
    "    l=[]\n",
    "    in_250=0\n",
    "    in_500=0\n",
    "\n",
    "    # Find nodes among the [5, 500] range top nodes that are also present among the top nodes of the other ranges\n",
    "    for n in top_nodes_dict[f\"G_{country}_5_300\"]:\n",
    "      if n in top_nodes_dict[f\"G_{country}_5_250\"]:\n",
    "        shared.append(n)\n",
    "        in_250+=1\n",
    "      if n in top_nodes_dict[f\"G_{country}_5_500\"]:\n",
    "        in_500+=1\n",
    "      if n not in shared:\n",
    "        shared.append(n) \n",
    "\n",
    "    # For each common node for a country its position among the top nodes is retrieved and stored in a dictionary\n",
    "    for s in shared: \n",
    "      position={}\n",
    "      position['300']=top_nodes_dict[f\"G_{country}_5_300\"].index(s)+1\n",
    "      try:\n",
    "        position['250']=top_nodes_dict[f\"G_{country}_5_250\"].index(s)+1\n",
    "      except:\n",
    "        position['250']='/' # Meaning the node is not present among top nodes in this range\n",
    "      try:\n",
    "        position['500']=top_nodes_dict[f\"G_{country}_5_500\"].index(s)+1\n",
    "      except:\n",
    "        position['500']='/'  \n",
    "      common_positions[s]=position\n",
    "    \n",
    "    # Values of the position of common nodes for each country are stored in a dictionary\n",
    "    common_nodes[f\"{country}\"]= common_positions    \n",
    "\n",
    "    # Function creating an HTML table for the results\n",
    "    def common_nodes_html(common_nodes, country): \n",
    "      html_table = \"<table border='1'>\"\n",
    "      html_table += \"<tr><th>Node</th><th> [5,300] Position</th><th>  [5,250] Position</th><th>[5,500] Position</th></tr>\"\n",
    "    \n",
    "      for key, value in common_nodes[country].items():\n",
    "        html_table += f\"<tr><td>{key}</td><td>{value['300']}</td> <td>{value['250']}</td><td>{value['500']}</td></tr>\"\n",
    "    \n",
    "      html_table += \"</table>\"\n",
    "      return html_table\n",
    "\n",
    "    # Create an HTML string for storing the information\n",
    "    html_string = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "      <meta charset=\"UTF-8\">\n",
    "      <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "      <title>Graph Information</title>\n",
    "    </head>\n",
    "    <body>\n",
    "      <h1>{country}: Comparison of nodes based on different ranges </h1>\n",
    "      <p>Number of nodes in the [5,300] range that are also in the [5,250] range: {in_250}</p>\n",
    "      <p>Number of nodes in the [5,300] range that are also in the [5,500] range: {in_500}</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    # Add the table to the HTML string\n",
    "    html_string+=common_nodes_html(common_nodes,country)\n",
    "\n",
    "    html_string+=\"</body>\\n</html>\"\n",
    "\n",
    "    # Save the HTML string to a file\n",
    "    file_name = f\"{country}_node_comparison_range_based.html\"\n",
    "    file_path = os.path.join(info_dir, file_name)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "      file.write(html_string)\n",
    "    # Print a confirmation message\n",
    "    print(f\"Comparison of nodes based on different ranges for {country} saved as {file_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD \n",
    "\n",
    "def electrification_percentage(graphs_dir, top_communities_partition):\n",
    "    \"\"\"\n",
    "    Calculates the electrification percentages of routes and deliveries for each step \n",
    "    of adding the top nodes to the electrification strategy.\n",
    "\n",
    "    Parameters:\n",
    "    graphs_dir (str): The directory path where the graph files are located.\n",
    "\n",
    "    Returns:\n",
    "    None: The function only prints the electrification percentages for each step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through all files in the graphs_dir\n",
    "    for file_name in os.listdir(graphs_dir):\n",
    "        # Ignore files ending with '_all.graphml' and hidden files (starting with '.')\n",
    "        if not file_name.endswith('_all.graphml') and not file_name.startswith('.'):\n",
    "            print(f\"Processing file: {file_name}\")  # Print the current file being processed\n",
    "\n",
    "            # Read the graph from the file and set its name attribute to the file_name\n",
    "            graph = nx.read_graphml(os.path.join(graphs_dir, file_name))\n",
    "            graph.name = file_name  # Set the graph name attribute\n",
    "\n",
    "            # Extract the country name, min_distance and max_distance from the file_name\n",
    "            _, country, min_distance, max_distance = file_name.split(\"_\")[:4]\n",
    "            max_distance = os.path.splitext(max_distance)[0]\n",
    "\n",
    "            # Read the all_graph file for the same country\n",
    "            all_graph_file_name = f\"G_{country}_all.graphml\"\n",
    "            all_graph = nx.read_graphml(os.path.join(graphs_dir, all_graph_file_name))\n",
    "\n",
    "            # Calculate the total number of routes and deliveries in the all_graph\n",
    "            total_routes = all_graph.number_of_edges()\n",
    "            total_deliveries = sum(data['route_count'] for _, _, data in all_graph.edges(data=True))\n",
    "\n",
    "            total_routes_subset = graph.number_of_edges()\n",
    "            total_deliveries_subset = sum(data['route_count'] for _, _, data in graph.edges(data=True))\n",
    "\n",
    "            # Get the top nodes using the calculate_visualize_top_nodes function\n",
    "            top_nodes = calculate_visualize_top_nodes(graph, top_communities_partition, save_outputs=False)\n",
    "\n",
    "            # Initialize lists to store the number of electrified routes and deliveries for each step\n",
    "            electrified_routes = []\n",
    "            electrified_deliveries = []\n",
    "            electrified_routes_percentage = []\n",
    "            electrified_deliveries_percentage = []\n",
    "            electrified_routes_subset_percentage = []\n",
    "            electrified_deliveries_subset_percentage = []\n",
    "\n",
    "            # Iterate through each step of adding the top nodes to the electrification strategy\n",
    "            for i in range(1, len(top_nodes) + 1):\n",
    "                # Get the top nodes to be electrified at the current step\n",
    "                current_top_nodes = top_nodes[:i]\n",
    "\n",
    "                # Initialize a set to store the electrified routes and a counter for electrified deliveries\n",
    "                routes_attached_to_top_nodes = set()\n",
    "                deliveries_attached_to_top_nodes = 0\n",
    "\n",
    "                # Iterate through all edges (routes) in the graph\n",
    "                for u, v, data in graph.edges(data=True):\n",
    "                    # If either endpoint of the route is in the current_top_nodes, add the route to the electrified set\n",
    "                    # and update the electrified deliveries counter\n",
    "                    if u in current_top_nodes or v in current_top_nodes:\n",
    "                        routes_attached_to_top_nodes.add((u, v))\n",
    "                        deliveries_attached_to_top_nodes += data['route_count']\n",
    "\n",
    "                # Update the electrified_routes and electrified_deliveries lists with the current step's values\n",
    "                electrified_routes.append(len(routes_attached_to_top_nodes))\n",
    "                electrified_deliveries.append(deliveries_attached_to_top_nodes)\n",
    "\n",
    "                # Calculate the electrification percentages for the current step\n",
    "                electrified_routes_percentage.append((len(routes_attached_to_top_nodes) / total_routes) * 100)\n",
    "                electrified_deliveries_percentage.append((deliveries_attached_to_top_nodes / total_deliveries) * 100)\n",
    "\n",
    "                electrified_routes_subset_percentage.append((len(routes_attached_to_top_nodes) / total_routes_subset) * 100)\n",
    "                electrified_deliveries_subset_percentage.append((deliveries_attached_to_top_nodes / total_deliveries_subset) * 100)\n",
    "\n",
    "                # Create an HTML table for the results\n",
    "                html_table = \"<table border='1'><tr><th>Node</th><th>Electrified Routes</th><th>% Electrification (Routes) Total</th><th>% Electrification (Routes) Subset</th><th>Electrified Deliveries</th><th>% Electrification (Deliveries) Total</th><th>% Electrification (Deliveries) Subset</th></tr>\"\n",
    "                for i, (node, routes, routes_percentage, routes_subset_percentage, deliveries, deliveries_percentage, deliveries_subset_percentage) in enumerate(zip(top_nodes, electrified_routes, electrified_routes_percentage, electrified_routes_subset_percentage, electrified_deliveries, electrified_deliveries_percentage, electrified_deliveries_subset_percentage), start=1):\n",
    "                    html_table += f\"<tr><td>{node}</td><td>{routes}</td><td>{routes_percentage:.2f}%</td><td>{routes_subset_percentage:.2f}%</td><td>{deliveries}</td><td>{deliveries_percentage:.2f}%</td><td>{deliveries_subset_percentage:.2f}%</td></tr>\"\n",
    "                html_table += \"</table>\"\n",
    "\n",
    "\n",
    "                # Save the HTML table to a file\n",
    "                with open(os.path.join(info_dir, f\"{country}_{min_distance}_{max_distance}_pareto_electrification.html\"), \"w\") as f:\n",
    "                    f.write(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electrification_percentage(graphs_dir, info_dir, top_communities_partition):\n",
    "    \"\"\"\n",
    "    Calculates the electrification percentages of routes and deliveries for each step \n",
    "    of adding the top nodes to the electrification strategy.\n",
    "\n",
    "    Parameters:\n",
    "    graphs_dir (str): The directory path where the graph files are located.\n",
    "\n",
    "    Returns:\n",
    "    None: The function only prints the electrification percentages for each step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through all files in the graphs_dir\n",
    "    for file_name in os.listdir(graphs_dir):\n",
    "        # Ignore files ending with '_all.graphml' and hidden files (starting with '.')\n",
    "        if not file_name.endswith('_all.graphml') and not file_name.startswith('.'):\n",
    "            print(f\"Processing file: {file_name}\")  # Print the current file being processed\n",
    "\n",
    "            # Read the graph from the file and set its name attribute to the file_name\n",
    "            graph = nx.read_graphml(os.path.join(graphs_dir, file_name))\n",
    "            graph.name = file_name  # Set the graph name attribute\n",
    "\n",
    "            # Convert the graph node coordinates to tuples of floats\n",
    "            graph = nx.relabel_nodes(graph, {node: tuple(map(float, node.strip('()').split(','))) for node in graph.nodes()})\n",
    "\n",
    "            # Extract the country name, min_distance and max_distance from the file_name\n",
    "            _, country, min_distance, max_distance = file_name.split(\"_\")[:4]\n",
    "            max_distance = os.path.splitext(max_distance)[0]\n",
    "\n",
    "            # Read the all_graph file for the same country\n",
    "            all_graph_file_name = f\"G_{country}_all.graphml\"\n",
    "            all_graph = nx.read_graphml(os.path.join(graphs_dir, all_graph_file_name))\n",
    "\n",
    "            # Calculate the total number of routes and deliveries in the all_graph\n",
    "            total_routes = all_graph.number_of_edges()\n",
    "            total_deliveries = sum(data['route_count'] for _, _, data in all_graph.edges(data=True))\n",
    "\n",
    "            total_routes_subset = graph.number_of_edges()\n",
    "            total_deliveries_subset = sum(data['route_count'] for _, _, data in graph.edges(data=True))\n",
    "\n",
    "            # Find the corresponding HTML file and extract the top nodes\n",
    "            html_file_name = f\"G_{country}_{min_distance}_{max_distance}.graphml_top_nodes_info.html\"\n",
    "            with open(os.path.join(info_dir, html_file_name), \"r\") as html_file:\n",
    "                soup = BeautifulSoup(html_file.read(), \"html.parser\")\n",
    "                top_nodes_table = soup.find(\"table\")\n",
    "                top_nodes = []\n",
    "                for row in top_nodes_table.findAll(\"tr\")[1:]:\n",
    "                    cell = row.findAll(\"td\")[0]\n",
    "                    node_coordinates = tuple(map(float, re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cell.text)))\n",
    "                    top_nodes.append(node_coordinates)\n",
    "\n",
    "            # Check if all top_nodes are present in the graph\n",
    "            missing_nodes = [node for node in top_nodes if node not in graph.nodes()]\n",
    "            if missing_nodes:\n",
    "                print(\"Missing nodes:\", missing_nodes)\n",
    "            else:\n",
    "                print(\"All top_nodes are present in the graph.\")\n",
    "\n",
    "            # Initialize lists to store the number of electrified routes and deliveries for each step\n",
    "            electrified_routes = []\n",
    "            electrified_deliveries = []\n",
    "            electrified_routes_percentage = []\n",
    "            electrified_deliveries_percentage = []\n",
    "            electrified_routes_subset_percentage = []\n",
    "            electrified_deliveries_subset_percentage = []\n",
    "\n",
    "            # Iterate through each step of adding the top nodes to the electrification strategy\n",
    "            for i in range(1, len(top_nodes) + 1):\n",
    "                # Get the top nodes to be electrified at the current step\n",
    "                current_top_nodes = top_nodes[:i]\n",
    "\n",
    "                # Initialize a set to store the electrified routes and a counter for electrified deliveries\n",
    "                routes_attached_to_top_nodes = set()\n",
    "                deliveries_attached_to_top_nodes = 0\n",
    "\n",
    "                # Iterate through all edges (routes) in the graph\n",
    "                for u, v, data in graph.edges(data=True):\n",
    "                    # If either endpoint of the route is in the current_top_nodes, add the route to the electrified set\n",
    "                    # and update the electrified deliveries counter\n",
    "                    if u in current_top_nodes or v in current_top_nodes:\n",
    "                        routes_attached_to_top_nodes.add((u, v))\n",
    "                        deliveries_attached_to_top_nodes += data['route_count']\n",
    "\n",
    "                # Update the electrified_routes and electrified_deliveries lists with the current step's values\n",
    "                electrified_routes.append(len(routes_attached_to_top_nodes))\n",
    "                electrified_deliveries.append(deliveries_attached_to_top_nodes)\n",
    "\n",
    "                # Calculate the electrification percentages for the current step\n",
    "                electrified_routes_percentage.append((len(routes_attached_to_top_nodes) / total_routes) * 100)\n",
    "                electrified_deliveries_percentage.append((deliveries_attached_to_top_nodes / total_deliveries) * 100)\n",
    "\n",
    "                electrified_routes_subset_percentage.append((len(routes_attached_to_top_nodes) / total_routes_subset) * 100)\n",
    "                electrified_deliveries_subset_percentage.append((deliveries_attached_to_top_nodes / total_deliveries_subset) * 100)\n",
    "\n",
    "                # Create an HTML table for the results\n",
    "                html_table = \"<table border='1'><tr><th>Node</th><th>Electrified Routes</th><th>% Electrification (Routes) Total</th><th>% Electrification (Routes) Subset</th><th>Electrified Deliveries</th><th>% Electrification (Deliveries) Total</th><th>% Electrification (Deliveries) Subset</th></tr>\"\n",
    "                for i, (node, routes, routes_percentage, routes_subset_percentage, deliveries, deliveries_percentage, deliveries_subset_percentage) in enumerate(zip(top_nodes, electrified_routes, electrified_routes_percentage, electrified_routes_subset_percentage, electrified_deliveries, electrified_deliveries_percentage, electrified_deliveries_subset_percentage), start=1):\n",
    "                    html_table += f\"<tr><td>{node}</td><td>{routes}</td><td>{routes_percentage:.2f}%</td><td>{routes_subset_percentage:.2f}%</td><td>{deliveries}</td><td>{deliveries_percentage:.2f}%</td><td>{deliveries_subset_percentage:.2f}%</td></tr>\"\n",
    "                html_table += \"</table>\"\n",
    "\n",
    "\n",
    "                # Save the HTML table to a file\n",
    "                with open(os.path.join(info_dir, f\"{country}_{min_distance}_{max_distance}_pareto_electrification.html\"), \"w\") as f:\n",
    "                    f.write(html_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: G_Belgium_5_300.graphml\n",
      "All top_nodes are present in the graph.\n",
      "Processing file: G_Denmark_5_300.graphml\n",
      "All top_nodes are present in the graph.\n"
     ]
    }
   ],
   "source": [
    "# Calling the functions \n",
    "electrification_percentage(graphs_dir, info_dir, top_communities_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General Calculations\n",
    "\n",
    "# Define the list of countries\n",
    "countries = ['United Kingdom', 'Sweden', 'Germany', 'Belgium', 'Netherlands', 'Denmark']\n",
    "\n",
    "# Initialize the HTML string\n",
    "html_str = \"<html>\\n<head></head>\\n<body>\\n\"\n",
    "\n",
    "# Calculate the percentages for each country\n",
    "for country in countries:\n",
    "    # Calculate the number of routes that depart from or arrive in the country\n",
    "    depart_routes = df_routes[df_routes['FromCountry'] == country].shape[0]\n",
    "    arrive_routes = df_routes[df_routes['ToCountry'] == country].shape[0]\n",
    "    total_routes = depart_routes + arrive_routes\n",
    "    \n",
    "    # Calculate the percentage of routes that depart from or arrive in the country\n",
    "    route_percent = total_routes / len(df_routes) * 100\n",
    "    \n",
    "    # Calculate the number of deliveries that depart from or arrive in the country\n",
    "    depart_deliveries = df_routes[df_routes['FromCountry'] == country]['RouteCount'].sum()\n",
    "    arrive_deliveries = df_routes[df_routes['ToCountry'] == country]['RouteCount'].sum()\n",
    "    total_deliveries = depart_deliveries + arrive_deliveries\n",
    "    \n",
    "    # Calculate the percentage of deliveries that depart from or arrive in the country\n",
    "    delivery_percent = total_deliveries / df_routes['RouteCount'].sum() * 100\n",
    "    \n",
    "    # Add the results for the country to the HTML string\n",
    "    html_str += f\"<h3>{country}</h3>\\n\"\n",
    "    html_str += f\"<p>Route percentage: {route_percent:.2f}%</p>\\n\"\n",
    "    html_str += f\"<p>Delivery percentage: {delivery_percent:.2f}%</p>\\n\"\n",
    "    html_str += \"<hr>\\n\"\n",
    "\n",
    "# Finalize the HTML string\n",
    "html_str += \"</body>\\n</html>\"\n",
    "\n",
    "# Write the HTML string to a file\n",
    "if not os.path.exists(info_dir):\n",
    "    os.makedirs(info_dir)\n",
    "\n",
    "with open(os.path.join(info_dir, \"general_info.html\"), \"w\") as f:\n",
    "    f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
